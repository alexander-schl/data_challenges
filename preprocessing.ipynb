{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d8c1fb-7ca1-49eb-8281-404952380d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a60e3b-da86-4fd0-a7ce-895973e8fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_and_remove_logo(image, logo_templates, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Detects and removes logos from an image using template matching + inpainting.\n",
    "    \n",
    "    Parameters:\n",
    "        image: Input image (BGR)\n",
    "        logo_templates: List of logo template images (BGR)\n",
    "        threshold: Match quality threshold (0â€“1, higher = stricter)\n",
    "    \n",
    "    Returns:\n",
    "        Cleaned image with logos removed if detected.\n",
    "    \"\"\"\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for template in templates:\n",
    "        if template is None:\n",
    "            continue  # Skip if template failed to load\n",
    "\n",
    "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Skip if template is larger than image\n",
    "        if template_gray.shape[0] > image_gray.shape[0] or template_gray.shape[1] > image_gray.shape[1]:\n",
    "            continue\n",
    "\n",
    "        res = cv2.matchTemplate(image_gray, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        loc = np.where(res >= threshold)\n",
    "\n",
    "        for pt in zip(*loc[::-1]):\n",
    "            h, w = template_gray.shape\n",
    "            cv2.rectangle(image, pt, (pt[0] + w, pt[1] + h), (255, 255, 255), thickness=cv2.FILLED)\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38a8e8a-1506-4e9c-b7ba-e676863243fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_irregular_coin_safe(image, target_size=(224, 224), margin=10, debug=False):\n",
    "    \"\"\"\n",
    "    Safely extracts irregular or partial coins using robust contour detection.\n",
    "    Keeps aspect ratio, adds transparency padding.\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply CLAHE for local contrast boost\n",
    "    clahe = cv2.createCLAHE(clipLimit=20.0, tileGridSize=(16, 16))\n",
    "    equalized = clahe.apply(gray)\n",
    "\n",
    "    # Then blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(equalized, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV, 9,2\n",
    "    )\n",
    "\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        print(\"No valid contours found.\")\n",
    "        return None\n",
    "\n",
    "    largest = max(contours, key=cv2.contourArea)\n",
    "    area = cv2.contourArea(largest)\n",
    "    if area < 100:  # ignore very small artifacts\n",
    "        print(\"Detected contour is too small.\")\n",
    "        return None\n",
    "\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.drawContours(mask, [largest], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    coin_only = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # crop to bounding box\n",
    "    x, y, w, h = cv2.boundingRect(largest)\n",
    "    x1 = max(x - margin, 0)\n",
    "    y1 = max(y - margin, 0)\n",
    "    x2 = min(x + w + margin, image.shape[1])\n",
    "    y2 = min(y + h + margin, image.shape[0])\n",
    "\n",
    "    coin_crop = coin_only[y1:y2, x1:x2]\n",
    "    mask_crop = mask[y1:y2, x1:x2]\n",
    "\n",
    "    coin_bgra = cv2.cvtColor(coin_crop, cv2.COLOR_BGR2BGRA)\n",
    "    coin_bgra[:, :, 3] = mask_crop\n",
    "\n",
    "    # keep ratio\n",
    "    h, w = coin_bgra.shape[:2]\n",
    "    scale = min(target_size[0] / h, target_size[1] / w)\n",
    "    new_w, new_h = int(w * scale), int(h * scale)\n",
    "    resized = cv2.resize(coin_bgra, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    final = np.zeros((target_size[1], target_size[0], 4), dtype=np.uint8)\n",
    "    x_offset = (target_size[0] - new_w) // 2\n",
    "    y_offset = (target_size[1] - new_h) // 2\n",
    "    final[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = resized\n",
    "\n",
    "    if debug:\n",
    "        cv2.imwrite(\"debug_mask.png\", mask)\n",
    "        cv2.imwrite(\"debug_thresh.png\", thresh)\n",
    "        cv2.imwrite(\"debug_cleaned.png\", cleaned)\n",
    "\n",
    "        \n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668148d5-06c8-48a5-a0b0-38e3a4408ac0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_paths = glob.glob(\"../bueschelquinare/*/*/*.jpg\")\n",
    "\n",
    "template1 = cv2.imread(\"muenzkabinett_berlin.png\")\n",
    "template2 = cv2.imread(\"cc-by-nc-sa.png\")\n",
    "templates = [template1, template2]\n",
    "\n",
    "for image_path in image_paths:\n",
    "    img = cv2.imread(image_path)\n",
    "    try:\n",
    "        cleaned_img = detect_and_remove_logo(img, templates)\n",
    "        extraced_coin_img = extract_irregular_coin_safe(cleaned_img)\n",
    "    except:\n",
    "        print(f\"Error: {image_path}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "    # extract alpha mask\n",
    "    alpha = extraced_coin_img[:, :, 3]\n",
    "    foreground = extraced_coin_img[:, :, :3]\n",
    "    masked = cv2.bitwise_and(foreground, foreground, mask=alpha)\n",
    "    gray_masked = cv2.cvtColor(masked, cv2.COLOR_BGR2GRAY)\n",
    "    gray_rgb = cv2.cvtColor(gray_masked, cv2.COLOR_GRAY2BGR)\n",
    "    gray_bgra = cv2.merge([gray_rgb, alpha])\n",
    "    image_path_to_save = image_path.replace(\"bueschelquinare\",\"bueschelquinare_preprocessed\")\n",
    "    image_path_to_save = image_path_to_save.replace(\".jpg\",\"_cropped_graymasked.png\")\n",
    "    if extraced_coin_img is not None:\n",
    "        cv2.imwrite(image_path_to_save, gray_bgra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2169be-040e-4301-bf26-e2e85b4afa4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
